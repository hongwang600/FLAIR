{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import random\n",
    "import textwrap\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToAscii:\n",
    "    def __init__(self, char_set='simple', width=64, height=64, density=1.0):\n",
    "        self.char_set = char_set\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.density = density\n",
    "        self.ascii_char_sets = {\n",
    "            'simple': '@%#*+=-:. ',\n",
    "            'complex': '$@B%8&WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\\|()1{}[]?-_+~<>i!lI;:,\"^`\\'. ',\n",
    "            'blocks': '█▓▒░ ',\n",
    "        }\n",
    "\n",
    "    def preprocess(self, image, brightness=1.0, saturation=1.0, sharpness=1.0, contrast=1.0, hue=0.0):\n",
    "        \"\"\"\n",
    "        Apply preprocessing to the image such as adjusting brightness, saturation, sharpness, contrast, and hue.\n",
    "        \"\"\"\n",
    "        if brightness != 1.0:\n",
    "            enhancer = ImageEnhance.Brightness(image)\n",
    "            image = enhancer.enhance(brightness)\n",
    "        \n",
    "        if saturation != 1.0:\n",
    "            enhancer = ImageEnhance.Color(image)\n",
    "            image = enhancer.enhance(saturation)\n",
    "        \n",
    "        if sharpness != 1.0:\n",
    "            enhancer = ImageEnhance.Sharpness(image)\n",
    "            image = enhancer.enhance(sharpness)\n",
    "        \n",
    "        if contrast != 1.0:\n",
    "            enhancer = ImageEnhance.Contrast(image)\n",
    "            image = enhancer.enhance(contrast)\n",
    "        \n",
    "        if hue != 0.0:\n",
    "            pass\n",
    "\n",
    "        return image\n",
    "\n",
    "    def resize_image(self, image):\n",
    "        return image.resize((self.width, self.height))\n",
    "\n",
    "    def adjust_space_density(self, line):\n",
    "        white_space = ' ' * int(1 / self.density)\n",
    "        return white_space.join(line)\n",
    "\n",
    "    def pixels_to_chars(self, image):\n",
    "        pixels = np.array(image)\n",
    "        chars = \"\".join([self.ascii_char_sets[self.char_set][pixel * len(self.ascii_char_sets[self.char_set]) // 256] \n",
    "                         for pixel in pixels.flatten()])\n",
    "        return chars\n",
    "\n",
    "    def generate(self, image_path, brightness=1.0, saturation=1.0, sharpness=1.0, contrast=1.0, hue=0.0):\n",
    "        image = Image.open(image_path)\n",
    "        image = self.preprocess(image, brightness, saturation, sharpness, contrast, hue)\n",
    "        image = self.resize_image(image)\n",
    "        image = image.convert(\"L\")  # Convert to grayscale\n",
    "        chars = self.pixels_to_chars(image)\n",
    "        ascii_art = \"\\n\".join([self.adjust_space_density(chars[index:index + self.width]) \n",
    "                               for index in range(0, len(chars), self.width)])\n",
    "        return ascii_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT:\n",
    "    def __init__(self, openai_client):\n",
    "        self.openai_client = openai_client\n",
    "        self.total_tokens = 0\n",
    "        self.cost = 0.0\n",
    "    \n",
    "    def num_tokens(self, string: str, encoding_name: str) -> int:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "\n",
    "    def gpt(self, prompt, max_tokens, temp, model):\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=prompt,\n",
    "            temperature=temp,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        response = response.choices[0].message.content\n",
    "        prompt_tokens = self.num_tokens(str(prompt), \"cl100k_base\")\n",
    "        response_tokens = self.num_tokens(str(response), \"cl100k_base\")\n",
    "\n",
    "        pricing = {\n",
    "            'gpt-4-0125-preview': {'input': 0.01, 'output': 0.03},\n",
    "            'gpt-4-1106-preview': {'input': 0.01, 'output': 0.03},\n",
    "            'gpt-4': {'input': 0.03, 'output': 0.06},\n",
    "            'gpt-4-32k': {'input': 0.06, 'output': 0.12},\n",
    "            'gpt-3.5-turbo-0125': {'input': 0.0005, 'output': 0.0015},\n",
    "            'gpt-3.5-turbo': {'input': 0.0030, 'output': 0.0060},\n",
    "        }\n",
    "\n",
    "        rates = pricing.get(model, {'input': 0.0, 'output': 0.0})\n",
    "\n",
    "        self.cost += (prompt_tokens * rates['input'] + response_tokens * rates['output']) / 1000\n",
    "        self.total_tokens += prompt_tokens + response_tokens\n",
    "\n",
    "        return response\n",
    "\n",
    "    def dalle(self, prompt, img_size, model):\n",
    "        pricing = {\n",
    "            ('dall-e-3', '1024x1024'): 0.040,\n",
    "            ('dall-e-3', '1024x1792'): 0.080,\n",
    "            ('dall-e-3', '1792x1024'): 0.080,\n",
    "            ('dall-e-2', '1024x1024'): 0.020,\n",
    "            ('dall-e-2', '512x512'): 0.018,\n",
    "            ('dall-e-2', '256x256'): 0.016,\n",
    "        }\n",
    "        cost_per_image = pricing.get((model, img_size), 0.0)\n",
    "\n",
    "        \n",
    "\n",
    "        response = self.openai_client.images.generate(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            size=img_size,\n",
    "            n=1,\n",
    "        )\n",
    "        print(prompt)\n",
    "\n",
    "        self.cost += cost_per_image\n",
    "        return response.data[0].url\n",
    "    \n",
    "    def gen_img_sequence(self, random_sequence, img_size, model):\n",
    "        prompts = []\n",
    "        for item in random_sequence:\n",
    "            prompt = [\n",
    "                {\"role\": \"user\", \"content\": textwrap.dedent(f\"\"\"\\\n",
    "                Instruction: Your task is optimize user's input for image generation.\n",
    "                Example User Input: Create an image of a single cat on a blank background. The background is completely white, emphasizing the cat's features.\n",
    "                Example Output: A single cat sitting on a completely white background, emphasizing its distinct features. The cat is fluffy with a rich, thick coat, displaying a variety of colors such as ginger, black, and white. Its eyes are large and expressive, colored a deep emerald green. The cat's pose is relaxed, with its tail curled around its paws.\n",
    "                User Input: Create an image of a single {item} on a blank background. The background is completely white, emphasizing the {item}'s features.\n",
    "                Output: \n",
    "                \"\"\")\n",
    "                }\n",
    "            ]\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        # optimize the prompt for better generation\n",
    "        optimized_prompts = []\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            futures = [executor.submit(self.gpt, prompt, 128, 0.7, 'gpt-4') for prompt in prompts]\n",
    "            for future in as_completed(futures):\n",
    "                optimized_prompts.append(future.result())\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            futures = [executor.submit(self.dalle, prompt, img_size, model) for prompt in optimized_prompts]\n",
    "            results = []\n",
    "            for future in as_completed(futures):\n",
    "                results.append(future.result())\n",
    "            return results\n",
    "\n",
    "    def extract_after_keyword(self, text, keyword=\"keyword\"):\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        # Pattern to match the keyword case-insensitively and capture the text after it\n",
    "        pattern = re.compile(r'\\b' + re.escape(keyword) + r':\\s*(.*)', re.IGNORECASE)\n",
    "\n",
    "        # Search for the pattern in the cleaned text\n",
    "        match = pattern.search(cleaned_text)\n",
    "\n",
    "        # If a match is found, return the captured group, otherwise return None\n",
    "        return match.group(1) if match else None\n",
    "\n",
    "    def gen_random_pair(self, examples):\n",
    "        prompt = [\n",
    "            {\"role\": \"user\", \"content\": textwrap.dedent(f\"\"\"\\\n",
    "            Instruction: Generate a Python list containing two visually simple and unrelated items. Each entity in the list should be distinct from each other and easily recognizable.\n",
    "            Examples: \n",
    "            [\"apple\", \"egg\"]\n",
    "            {examples}\n",
    "            You Output (one python list that contains two random entities): \n",
    "            \"\"\")\n",
    "            }\n",
    "        ]\n",
    "        answer = self.gpt(prompt, 128, 0.7, 'gpt-4')\n",
    "        return answer\n",
    "\n",
    "    def gen_random_sequence(self, random_pair):\n",
    "        while True:\n",
    "            sequence = []\n",
    "            for _ in range(4):\n",
    "                sequence.append(random.choice(random_pair))\n",
    "            if len(set(sequence)) > 1:\n",
    "                return sequence\n",
    "\n",
    "    def download_and_save_images(self, urls, folder_name):\n",
    "        os.makedirs(folder_name, exist_ok=True)\n",
    "        filenames = ['A.png', 'B.png', 'C.png', 'D.png']\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            futures = []\n",
    "            for url, filename in zip(urls, filenames):\n",
    "                path = os.path.join(folder_name, filename)\n",
    "                futures.append(executor.submit(self.download_image, url, path))\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                future.result()\n",
    "\n",
    "    def download_image(self, url, path):\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  \n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "\n",
    "\n",
    "openai_client = OpenAI(api_key='none')\n",
    "model = GPT(openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single car showcased on a completely white background, accentuating its distinct features. The car is sleek, with a glossy, polished finish that reflects light brilliantly. It sports a vibrant, red color that contrasts starkly against the white backdrop. The car's design is aerodynamic, with curved lines and an overall streamlined shape. Its headlights are bright and clear, while the wheels are large and sturdy. The car appears luxurious and high-end, highlighting the elegance of automotive design.\n",
      "A single car positioned on a completely white background, emphasizing its striking features. The car is sleek and polished, with a glossy finish that reflects light beautifully. It displays a vibrant, red hue, which contrasts dramatically against the white backdrop. The car's design is aerodynamic, with smooth, curvaceous lines and polished chrome detailing. Its wheels are large and robust, giving it a sturdy and powerful stance. The headlights are bright and clear, adding to the overall aesthetic appeal of the car.\n",
      "A single car positioned on a stark white background, accentuating its design elements. The car boasts a sleek, aerodynamic shape, painted in a glossy red that stands out against the background. Its headlights are modern and sharp, while the chrome-plated rims catch the light. The car's stance is dynamic, suggesting movement even in stillness.\n",
      "A single book placed on a completely white background, emphasizing its unique characteristics. The book cover is hardbound, with deep, rich hues of royal blue and gold. The title is embossed in gold lettering, creating a striking contrast. The pages are slightly worn, indicating that the book has been lovingly read many times. The book is positioned upright, showcasing its thick spine and well-crafted cover design.\n"
     ]
    }
   ],
   "source": [
    "# generate random image captcha\n",
    "n_samples = 100\n",
    "\n",
    "previous_samples = []\n",
    "for i in range(n_samples):\n",
    "    previous_10_samples = previous_samples[-10:]\n",
    "    prompt_examples = \"\"\n",
    "    for sample in previous_10_samples:\n",
    "        prompt_examples += sample+\"\\n\"\n",
    "\n",
    "    random_pair = model.gen_random_pair(prompt_examples)\n",
    "    previous_samples.append(random_pair)\n",
    "\n",
    "    random_pair = json.loads(random_pair)\n",
    "    random_sequence = model.gen_random_sequence(random_pair)\n",
    "    img_urls = model.gen_img_sequence(random_sequence, '1024x1024', 'dall-e-3')\n",
    "\n",
    "    folder = f\"samples/{'-'.join(random_pair)}\"\n",
    "    model.download_and_save_images(img_urls, folder)\n",
    "    with open(folder+'/obj.json', 'w') as file:\n",
    "        json.dump(random_sequence, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./samples\"\n",
    "converter = ImageToAscii(char_set='simple', width=64, height=64, density=2)\n",
    "for subdir in os.listdir(root_dir):\n",
    "    subdir_path = os.path.join(root_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for image_file in os.listdir(subdir_path):\n",
    "            if image_file.endswith('.png'):\n",
    "                file_path = os.path.join(subdir_path, image_file)\n",
    "                ascii_art = converter.generate(file_path)\n",
    "                text_file = os.path.splitext(file_path)[0] + '.txt'\n",
    "                with open(text_file, 'w') as f:\n",
    "                    f.write(ascii_art)\n",
    "                print(f\"Generated ASCII art for {image_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ascii select\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2478fc7d01187446f448a2def029a9fdec9a2e6a7ec3142a090ad05f79833d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
